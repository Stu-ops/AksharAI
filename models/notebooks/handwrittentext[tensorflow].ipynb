{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this was notice to replace the download from the github make your own model dataset into huggingface\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBnM-vtF5luC"
   },
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/datasets/sameernotes/sakshi-handwriting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# title training\n",
    "# Step 1: Import Libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from google.colab import files  # preface for uploading files but recommended to use os methode to download files\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.font_manager as fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Verify GPU Availability\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU Available:\", tf.test.is_gpu_available())\n",
    "print(\"Using T4 GPU:\", tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Install a Devanagari Font\n",
    "url = \"https://github.com/googlefonts/noto-fonts/raw/main/hinted/ttf/NotoSansDevanagari/NotoSansDevanagari-Regular.ttf\"\n",
    "font_path = \"[FONT_PATH]\"  # Replace with your desired font path\n",
    "r = requests.get(url)  # import requests\n",
    "with open(font_path, \"wb\") as f:\n",
    "    f.write(r.content)\n",
    "font_path = 'C:/Coding/ocr_model/NotoSansDevanagari-Regular.ttf'   \n",
    "fm.fontManager.addfont(font_path)\n",
    "plt.rcParams['font.family'] = 'Noto Sans Devanagari'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Load Words and Images (No Upload Needed)\n",
    "with open('/content/words.txt', 'r', encoding='utf-8') as f:\n",
    "    words = f.read().splitlines()\n",
    "\n",
    "image_dir = '/content/images'\n",
    "images = []\n",
    "for i in range(1, 36):  # 1.png to 35.png\n",
    "    img_path = os.path.join(image_dir, f'{i}.png')\n",
    "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (128, 32))  # Resize to fixed size\n",
    "    img = img / 255.0  # Normalize\n",
    "    images.append(img)\n",
    "\n",
    "images = np.array(images)\n",
    "images = images[..., np.newaxis]  # Add channel dimension: (35, 128, 32, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode Labels\n",
    "label_encoder = LabelEncoder()\n",
    "labels = label_encoder.fit_transform(words)\n",
    "\n",
    "# Step 6: Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=10,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate augmented data\n",
    "augmented_images = []\n",
    "augmented_labels = []\n",
    "for i in range(len(images)):\n",
    "    img = images[i]\n",
    "    lbl = labels[i]\n",
    "    img = img[np.newaxis, ...]  # Add batch dimension for datagen\n",
    "    for _ in range(5):  # Generate 5 augmented versions per image\n",
    "        aug_img = next(datagen.flow(img, batch_size=1))[0]\n",
    "        augmented_images.append(aug_img)\n",
    "        augmented_labels.append(lbl)\n",
    "\n",
    "augmented_images = np.array(augmented_images)\n",
    "augmented_labels = np.array(augmented_labels)\n",
    "\n",
    "# Combine original and augmented data\n",
    "X = np.concatenate([images, augmented_images], axis=0)\n",
    "y = np.concatenate([labels, augmented_labels], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 26631,
     "status": "ok",
     "timestamp": 1742315437575,
     "user": {
      "displayName": "sameer banchhor",
      "userId": "01803110325086599414"
     },
     "user_tz": -330
    },
    "id": "eoYUCpjcxZQv",
    "outputId": "98637d76-3a29-45b5-d356-cc9550975785"
   },
   "outputs": [],
   "source": [
    "# Step 7: Split Data (80% train, 20% test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 8: Build CNN Model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 32, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dropout(0.5),  # Prevent overfitting\n",
    "    layers.Dense(35, activation='softmax')  # 35 classes\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Step 9: Train the Model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test))\n",
    "\n",
    "# Step 10: Evaluate the Model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n",
    "\n",
    "# Step 11: Plot Training History\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 12: Save the Model (Using .keras format)\n",
    "model.save('hindi_ocr_model.keras')\n",
    "files.download('hindi_ocr_model.keras')  # Download to your local machine\n",
    "\n",
    "# Step 13: Test on a Sample Image\n",
    "sample_img = X_test[0][np.newaxis, ...]  # Take first test image\n",
    "pred = model.predict(sample_img)\n",
    "pred_label = label_encoder.inverse_transform([np.argmax(pred)])[0]\n",
    "print(f\"Predicted Word: {pred_label}\")\n",
    "plt.imshow(X_test[0].squeeze(), cmap='gray')\n",
    "plt.title(f\"Predicted: {pred_label}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 624,
     "status": "ok",
     "timestamp": 1742315445862,
     "user": {
      "displayName": "sameer banchhor",
      "userId": "01803110325086599414"
     },
     "user_tz": -330
    },
    "id": "iyJx1qHA1Kpc"
   },
   "outputs": [],
   "source": [
    "# @title save indexer\n",
    "import pickle\n",
    "\n",
    "with open('/content/label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D54qI_Ks1UaJ"
   },
   "outputs": [],
   "source": [
    "# @title test model\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import os\n",
    "!wget https://github.com/googlefonts/noto-fonts/raw/main/hinted/ttf/NotoSansDevanagari/NotoSansDevanagari-Regular.ttf -O /usr/share/fonts/truetype/NotoSansDevanagari-Regular.ttf\n",
    "font_path = '[FONT_PATH]'  # Replace with your desired font path\n",
    "fm.fontManager.addfont(font_path)\n",
    "plt.rcParams['font.family'] = 'Noto Sans Devanagari'\n",
    "model_path = '/content/hindi_ocr_model.keras'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "print(\"Model loaded successfully from\", model_path)\n",
    "encoder_path = '/content/label_encoder.pkl'\n",
    "if not os.path.exists(encoder_path):\n",
    "    raise FileNotFoundError(f\"Label encoder {encoder_path} not found. Upload it or use numeric output.\")\n",
    "with open(encoder_path, 'rb') as f:\n",
    "    label_encoder = pickle.load(f)\n",
    "print(\"Label encoder loaded successfully from\", encoder_path)\n",
    "image_path = '/content/images/36.png'\n",
    "if not os.path.exists(image_path):\n",
    "    raise FileNotFoundError(f\"Image {image_path} not found. Ensure itâ€™s in /content/images/\")\n",
    "\n",
    "img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "img = cv2.resize(img, (128, 32))  # Resize to match training input size\n",
    "img = img / 255.0  # Normalize\n",
    "img = img[np.newaxis, ..., np.newaxis]  # Add batch and channel dimensions: (1, 128, 32, 1)\n",
    "pred = model.predict(img)\n",
    "pred_label_idx = np.argmax(pred)\n",
    "pred_label = label_encoder.inverse_transform([pred_label_idx])[0]\n",
    "print(f\"Predicted Word for 2.png: {pred_label}\")\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(f\"Predicted: {pred_label}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
